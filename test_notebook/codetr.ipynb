{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co Detr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic  \n",
    "\n",
    "@register_cell_magic  \n",
    "def locals(line, cell):  \n",
    "    \"\"\"  \n",
    "    用法：  \n",
    "    1. %%locals --skip   # 当前cell的代码不会被执行  \n",
    "    2. %%locals         # 当前cell在隔离环境执行，不会污染kernel变量  \n",
    "    \"\"\"  \n",
    "    line = line.split(\"#\")[0]\n",
    "    if '--skip' in line:  \n",
    "        return  \n",
    "    else:  \n",
    "        local_env = {}  \n",
    "        exec(cell, {}, local_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-09 23:20:50.935 | INFO     | hq_det.trainer:run:191 - data_path='/root/autodl-tmp/chengdu_v2_dataset' num_epoches=10 warmup_epochs=2 num_data_workers=8 lr0=0.0002 lr_min=1e-05 lr_backbone_mult=0.1 batch_size=2 device='cuda:0' checkpoint_path='/root/autodl-tmp/codetr/output' output_path='/root/autodl-tmp/codetr/output' checkpoint_interval=-1 model_argument={'model': '/root/autodl-tmp/model/codetr/co_dino_5scale_r50_1x_coco-7481f903.pth'} image_size=1024 enable_amp=False gradient_update_interval=1 class_id2names=None eval_class_names=[] devices=[0]\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "2025-06-09 23:20:50.970 | INFO     | hq_det.dataset:__init__:118 - CocoDetection: img_folder /root/autodl-tmp/chengdu_v2_dataset/train using 3204 images\n",
      "2025-06-09 23:20:50.970 | INFO     | hq_det.dataset:__init__:124 - id 2 names {0: '其他', 1: '划伤', 2: '划痕', 3: '压痕', 4: '吊紧', 5: '异物外漏', 6: '折痕', 7: '抛线', 8: '拼接间隙', 9: '水渍', 10: '水珠', 11: '烫伤', 12: '爆针线', 13: '白点', 14: '破损', 15: '碰伤', 16: '红标签', 17: '线头', 18: '脏污', 19: '褶皱(贯穿)', 20: '褶皱（轻度）', 21: '褶皱（重度）', 22: '重跳针'}\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "2025-06-09 23:20:50.978 | INFO     | hq_det.dataset:__init__:118 - CocoDetection: img_folder /root/autodl-tmp/chengdu_v2_dataset/valid using 802 images\n",
      "2025-06-09 23:20:50.978 | INFO     | hq_det.dataset:__init__:124 - id 2 names {0: '其他', 1: '划伤', 2: '划痕', 3: '压痕', 4: '吊紧', 5: '异物外漏', 6: '折痕', 7: '抛线', 8: '拼接间隙', 9: '水渍', 10: '水珠', 11: '烫伤', 12: '爆针线', 13: '白点', 14: '破损', 15: '碰伤', 16: '红标签', 17: '线头', 18: '脏污', 19: '褶皱(贯穿)', 20: '褶皱（轻度）', 21: '褶皱（重度）', 22: '重跳针'}\n",
      "/root/hq_det/hq_det/models/codetr\n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "rpn_conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "rpn_conv.bias - torch.Size([256]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "rpn_cls.weight - torch.Size([9, 256, 1, 1]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "rpn_cls.bias - torch.Size([9]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "rpn_reg.weight - torch.Size([36, 256, 1, 1]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "rpn_reg.bias - torch.Size([36]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.fc_cls.weight - torch.Size([24, 1024]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.fc_cls.bias - torch.Size([24]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.fc_reg.weight - torch.Size([92, 1024]): \n",
      "NormalInit: mean=0, std=0.001, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.fc_reg.bias - torch.Size([92]): \n",
      "NormalInit: mean=0, std=0.001, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.shared_fcs.0.bias - torch.Size([1024]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.shared_fcs.1.bias - torch.Size([1024]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "/root/mmdetection/mmdet/models/dense_heads/anchor_head.py:108: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "cls_convs.0.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "cls_convs.0.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "reg_convs.0.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "reg_convs.0.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "atss_cls.weight - torch.Size([23, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "atss_cls.bias - torch.Size([23]): \n",
      "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "atss_reg.weight - torch.Size([4, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "atss_reg.bias - torch.Size([4]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "atss_centerness.weight - torch.Size([1, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "atss_centerness.bias - torch.Size([1]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "scales.0.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "scales.1.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "scales.2.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "scales.3.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "scales.4.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "06/09 23:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "scales.5.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "CoDETR(\n",
      "  (data_preprocessor): DetDataPreprocessor()\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): ResLayer(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): ResLayer(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): ResLayer(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): ResLayer(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
      "  (neck): ChannelMapper(\n",
      "    (convs): ModuleList(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): ConvModule(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (2): ConvModule(\n",
      "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (3): ConvModule(\n",
      "        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (extra_convs): ModuleList(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "  (query_head): CoDINOHead(\n",
      "    (loss_cls): QualityFocalLoss()\n",
      "    (loss_bbox): L1Loss()\n",
      "    (loss_iou): GIoULoss()\n",
      "    (transformer): CoDinoTransformer(\n",
      "      (encoder): DetrTransformerEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0-5): 6 x BaseTransformerLayer(\n",
      "            (attentions): ModuleList(\n",
      "              (0): MultiScaleDeformableAttention(\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (sampling_offsets): Linear(in_features=256, out_features=320, bias=True)\n",
      "                (attention_weights): Linear(in_features=256, out_features=160, bias=True)\n",
      "                (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "                (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (ffns): ModuleList(\n",
      "              (0): FFN(\n",
      "                (layers): Sequential(\n",
      "                  (0): Sequential(\n",
      "                    (0): Linear(in_features=256, out_features=2048, bias=True)\n",
      "                    (1): ReLU(inplace=True)\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (1): Linear(in_features=2048, out_features=256, bias=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dropout_layer): Identity()\n",
      "                (gamma2): Identity()\n",
      "              )\n",
      "            )\n",
      "            (norms): ModuleList(\n",
      "              (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoder): DinoTransformerDecoder(\n",
      "        (layers): ModuleList(\n",
      "          (0-5): 6 x DetrTransformerDecoderLayer(\n",
      "            (attentions): ModuleList(\n",
      "              (0): MultiheadAttention(\n",
      "                (attn): MultiheadAttention(\n",
      "                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (dropout_layer): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (1): MultiScaleDeformableAttention(\n",
      "                (dropout): Dropout(p=0.0, inplace=False)\n",
      "                (sampling_offsets): Linear(in_features=256, out_features=320, bias=True)\n",
      "                (attention_weights): Linear(in_features=256, out_features=160, bias=True)\n",
      "                (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "                (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              )\n",
      "            )\n",
      "            (ffns): ModuleList(\n",
      "              (0): FFN(\n",
      "                (layers): Sequential(\n",
      "                  (0): Sequential(\n",
      "                    (0): Linear(in_features=256, out_features=2048, bias=True)\n",
      "                    (1): ReLU(inplace=True)\n",
      "                    (2): Dropout(p=0.0, inplace=False)\n",
      "                  )\n",
      "                  (1): Linear(in_features=2048, out_features=256, bias=True)\n",
      "                  (2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dropout_layer): Identity()\n",
      "                (gamma2): Identity()\n",
      "              )\n",
      "            )\n",
      "            (norms): ModuleList(\n",
      "              (0-2): 3 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ref_point_head): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (enc_output): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (enc_output_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (query_embed): Embedding(900, 256)\n",
      "      (aux_pos_trans): ModuleList(\n",
      "        (0-1): 2 x Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (aux_pos_trans_norm): ModuleList(\n",
      "        (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (pos_feats_trans): ModuleList()\n",
      "      (pos_feats_norm): ModuleList()\n",
      "    )\n",
      "    (cls_branches): ModuleList(\n",
      "      (0-6): 7 x Linear(in_features=256, out_features=23, bias=True)\n",
      "    )\n",
      "    (reg_branches): ModuleList(\n",
      "      (0-6): 7 x Sequential(\n",
      "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=256, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "    )\n",
      "    (activate): ReLU(inplace=True)\n",
      "    (positional_encoding): SinePositionalEncoding(num_feats=128, temperature=20, normalize=True, scale=6.283185307179586, eps=1e-06)\n",
      "    (dn_generator): CdnQueryGenerator(\n",
      "      (label_embedding): Embedding(23, 256)\n",
      "    )\n",
      "  )\n",
      "  (rpn_head): RPNHead(\n",
      "    (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n",
      "    (loss_bbox): L1Loss()\n",
      "    (rpn_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (rpn_cls): Conv2d(256, 9, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (rpn_reg): Conv2d(256, 36, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
      "  (roi_head): ModuleList(\n",
      "    (0): CoStandardRoIHead(\n",
      "      (bbox_roi_extractor): SingleRoIExtractor(\n",
      "        (roi_layers): ModuleList(\n",
      "          (0): RoIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
      "          (1): RoIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
      "          (2): RoIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
      "          (3): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
      "          (4): RoIAlign(output_size=(7, 7), spatial_scale=0.015625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
      "        )\n",
      "      )\n",
      "      (bbox_head): Shared2FCBBoxHead(\n",
      "        (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n",
      "        (loss_bbox): GIoULoss()\n",
      "        (fc_cls): Linear(in_features=1024, out_features=24, bias=True)\n",
      "        (fc_reg): Linear(in_features=1024, out_features=92, bias=True)\n",
      "        (shared_convs): ModuleList()\n",
      "        (shared_fcs): ModuleList(\n",
      "          (0): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "          (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (cls_convs): ModuleList()\n",
      "        (cls_fcs): ModuleList()\n",
      "        (reg_convs): ModuleList()\n",
      "        (reg_fcs): ModuleList()\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
      "    )\n",
      "  )\n",
      "  (bbox_head): ModuleList(\n",
      "    (0): CoATSSHead(\n",
      "      (loss_cls): FocalLoss()\n",
      "      (loss_bbox): GIoULoss()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (cls_convs): ModuleList(\n",
      "        (0): ConvModule(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (reg_convs): ModuleList(\n",
      "        (0): ConvModule(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (atss_cls): Conv2d(256, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (atss_reg): Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (atss_centerness): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (scales): ModuleList(\n",
      "        (0-5): 6 x Scale()\n",
      "      )\n",
      "      (loss_centerness): CrossEntropyLoss(avg_non_ignore=False)\n",
      "    )\n",
      "    init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'atss_cls', 'std': 0.01, 'bias_prob': 0.01}}\n",
      "  )\n",
      ")\n",
      "2025-06-09 23:20:56.379 | INFO     | hq_det.models.codetr.hq_codetr:load_model:70 - Loaded 653/674 parameters\n",
      "Train Epoch[0/11]:   0%|          | 0/1602 [00:00<?, ?it/s]/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/root/miniconda3/lib/python3.12/site-packages/mmcv/cnn/bricks/transformer.py:819: UserWarning: Use same attn_mask in all attentions in DetrTransformerDecoderLayer \n",
      "  warnings.warn(f'Use same attn_mask in all attentions in '\n",
      "/root/mmdetection/mmdet/models/task_modules/samplers/sampling_result.py:126: UserWarning: DeprecationWarning: bboxes is deprecated, please use \"priors\" instead\n",
      "  warnings.warn('DeprecationWarning: bboxes is deprecated, '\n",
      "Train Epoch[0/11]:   6%|5         | 94/1602 [01:46<27:22,  1.09s/it, box=0.101, cls=0.839, giou=0.936, loss=76.5] /root/miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Train Epoch[0/11]: 100%|##########| 1602/1602 [29:45<00:00,  1.11s/it, box=0.223, cls=0.549, giou=0.781, loss=60.9] \n",
      "Valid Epoch[0/11]: 100%|##########| 401/401 [02:37<00:00,  2.55it/s, box=0, cls=0, giou=0, loss=0]\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.10s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.50s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.130\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.265\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.120\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.423\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.359\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.515\n",
      "2025-06-09 23:53:26.052 | INFO     | hq_det.trainer:run:384 - Epoch 0, lr: 0.000181, lr_backbone: 1.8100000000000003e-05, train loss: 60.35594830826185, valid loss: 0.0, loss: 0.00,cls: 0.00,box: 0.00,giou: 0.00\n",
      "2025-06-09 23:53:26.053 | INFO     | hq_det.trainer:run:388 - Elapsed Time: Train 00:29:45 | Valid 00:02:37 | Epoch 00:32:22\n",
      "Train Epoch[1/11]: 100%|##########| 1602/1602 [29:41<00:00,  1.11s/it, box=0.0769, cls=0.133, giou=1.11, loss=41.6]  \n",
      "Valid Epoch[1/11]: 100%|##########| 401/401 [02:37<00:00,  2.54it/s, box=0, cls=0, giou=0, loss=0]\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.07s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.70s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.344\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.144\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.135\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.474\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.564\n",
      "2025-06-10 00:25:52.733 | INFO     | hq_det.trainer:run:384 - Epoch 1, lr: 0.000181, lr_backbone: 1.8100000000000003e-05, train loss: 51.00808194351758, valid loss: 0.0, loss: 0.00,cls: 0.00,box: 0.00,giou: 0.00\n",
      "2025-06-10 00:25:52.733 | INFO     | hq_det.trainer:run:388 - Elapsed Time: Train 00:29:41 | Valid 00:02:37 | Epoch 00:32:19\n",
      "Train Epoch[2/11]: 100%|##########| 1602/1602 [29:41<00:00,  1.11s/it, box=0.238, cls=0.361, giou=0.797, loss=48.4]  \n",
      "Valid Epoch[2/11]: 100%|##########| 401/401 [02:38<00:00,  2.54it/s, box=0, cls=0, giou=0, loss=0]\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.13s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.73s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.333\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.116\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.322\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.474\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.529\n",
      "2025-06-10 00:58:20.039 | INFO     | hq_det.trainer:run:384 - Epoch 2, lr: 0.000181, lr_backbone: 1.8100000000000003e-05, train loss: 47.95163841405593, valid loss: 0.0, loss: 0.00,cls: 0.00,box: 0.00,giou: 0.00\n",
      "2025-06-10 00:58:20.039 | INFO     | hq_det.trainer:run:388 - Elapsed Time: Train 00:29:41 | Valid 00:02:38 | Epoch 00:32:19\n",
      "Train Epoch[3/11]:  83%|########2 | 1325/1602 [24:37<05:14,  1.14s/it, box=0.0845, cls=0.406, giou=0.482, loss=39.2] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/IPython/utils/_process_posix.py:156\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pexpect/spawnbase.py:383\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/root/hq_det\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpython scripts/run_train_codetr.py      --data_path /root/autodl-tmp/chengdu_v2_dataset      --output_path /root/autodl-tmp/codetr/output      --load_checkpoint /root/autodl-tmp/model/codetr/co_dino_5scale_r50_1x_coco-7481f903.pth      --num_epoches 10      --warmup_epochs 2      --num_data_workers 8      --lr0 2e-4      --lr_min 1e-5      --batch_size 2      --device cuda:0      --checkpoint_interval -1      --image_size 1024\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/IPython/utils/_process_posix.py:180\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;66;03m# Ensure the subprocess really is terminated\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m         \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# add isalive check, to ensure exitstatus is set:\u001b[39;00m\n\u001b[1;32m    182\u001b[0m child\u001b[38;5;241m.\u001b[39misalive()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pexpect/pty_spawn.py:646\u001b[0m, in \u001b[0;36mspawn.terminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill(signal\u001b[38;5;241m.\u001b[39mSIGCONT)\n\u001b[0;32m--> 646\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayafterterminate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misalive():\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%locals  --skip\n",
    "import os\n",
    "os.chdir('/root/hq_det')\n",
    "\n",
    "!python scripts/run_train_codetr.py \\\n",
    "    --data_path /root/autodl-tmp/chengdu_v2_dataset \\\n",
    "    --output_path /root/autodl-tmp/codetr/output \\\n",
    "    --load_checkpoint /root/autodl-tmp/model/codetr/co_dino_5scale_r50_1x_coco-7481f903.pth \\\n",
    "    --num_epoches 10 \\\n",
    "    --warmup_epochs 2 \\\n",
    "    --num_data_workers 8 \\\n",
    "    --lr0 2e-4 \\\n",
    "    --lr_min 1e-5 \\\n",
    "    --batch_size 2 \\\n",
    "    --device cuda:0 \\\n",
    "    --checkpoint_interval -1 \\\n",
    "    --image_size 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%locals --skip\n",
    "import os\n",
    "os.chdir('/root/hq_det')\n",
    "from scripts.run_train_codetr import run_train_codetr, get_args\n",
    "\n",
    "args = get_args(use_kwargs=True, \n",
    "    batch_size=1, \n",
    "    num_epoches=1, \n",
    "    data_path='/root/autodl-tmp/chengdu_v2_dataset', \n",
    "    output_path='/root/autodl-tmp/codetr/output', \n",
    "    load_checkpoint='/root/autodl-tmp/model/codetr/co_dino_5scale_swin_large_16e_o365tococo-614254c9.pth',\n",
    "    device='cuda:0', \n",
    "    checkpoint_interval=-1, \n",
    "    image_size=1024\n",
    ")\n",
    "print(args.__dict__)\n",
    "\n",
    "run_train_codetr(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%locals #--skip\n",
    "import os\n",
    "os.chdir('/root/mmdetection')\n",
    "\n",
    "\n",
    "!python tools/train.py \\\n",
    "    /root/hq_det/test_notebook/configs/co_dino_5scale_swin_l_16xb1_16e_o365tococo.py \\\n",
    "    --work-dir /root/autodl-tmp/codetr/output \\\n",
    "    # --load_from /root/autodl-tmp/model/codetr/co_dino_5scale_swin_large_16e_o365tococo-614254c9.pth \\\n",
    "    # --num_epochs 10 \\\n",
    "    # --batch_size 4 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat tools/train.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%locals\n",
    "import os\n",
    "os.chdir('/root/mmdetection')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
